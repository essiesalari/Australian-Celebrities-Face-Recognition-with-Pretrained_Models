{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO8q83stZETZzRDr86w3UPM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/essiesalari/Australian-Celebrities-Face-Recognition-VGG16/blob/main/Australian_Celebrities_Face_Recognition_VGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Australian Celebrities Face Recognition-VGG16**"
      ],
      "metadata": {
        "id": "cOvOB2b2dgjU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "JIItkN255_5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "wdTvIkS6dgLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import datatset"
      ],
      "metadata": {
        "id": "8qbPBgm56EKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install bing_image_downloader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iA9AJtLFwdFN",
        "outputId": "e6a46b2f-42e7-4e6f-8c96-73f860b28ef2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bing_image_downloader in /usr/local/lib/python3.10/dist-packages (1.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bing_image_downloader import downloader"
      ],
      "metadata": {
        "id": "HQ2H3UTIwdZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Query\n",
        "search_queries=[\n",
        "    'Nicole Kidman',\n",
        "    'Mel Gibson',\n",
        "    'Liam Hemsworth',\n",
        "    'Cathy Freeman',\n",
        "    'Margot Robbie'\n",
        "]\n",
        "\n",
        "dataset_path = 'dataset'\n",
        "\n",
        "# Imgae downloder function\n",
        "def donwloader(query, n_sample, dataset_name):\n",
        "  downloader.download(query, limit=n_sample, output_dir=os.path.join(dataset_path, dataset_name))\n",
        "\n",
        "for query in search_queries:\n",
        "  donwloader(query, n_sample=20, dataset_name='train')\n",
        "  donwloader(query, n_sample=10, dataset_name='val')\n",
        "  donwloader(query, n_sample=3, dataset_name='test')"
      ],
      "metadata": {
        "id": "nO8YtfFswx-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path='/content/dataset'\n",
        "train_path = os.path.join(dataset_path, 'train')\n",
        "val_path = os.path.join(dataset_path, 'val')\n",
        "test_path = os.path.join(dataset_path, 'test')"
      ],
      "metadata": {
        "id": "xU7c72eAz6wj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nr_files = nr_train_files = nr_val_files = nr_test_files = 0\n",
        "\n",
        "for root, dirc, files in os.walk(dataset_path):\n",
        "  nr_files += len(files)\n",
        "print(\"#files: \", nr_files)\n",
        "for root, dirc, files in os.walk(train_path):\n",
        "  nr_train_files += len(files)\n",
        "print(\"#train_files: \", nr_train_files)\n",
        "for root, dirc, files in os.walk(val_path):\n",
        "  nr_val_files += len(files)\n",
        "print(\"#val_files: \", nr_val_files)\n",
        "for root, dirc, files in os.walk(test_path):\n",
        "  nr_test_files += len(files)\n",
        "print(\"#test_files: \", nr_test_files)"
      ],
      "metadata": {
        "id": "shBrPFKcy2eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15c7cadb-c2cf-49c8-fbaa-b158d3bbe441"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#files:  169\n",
            "#train_files:  107\n",
            "#val_files:  50\n",
            "#test_files:  12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build  a New Model based on VGG16"
      ],
      "metadata": {
        "id": "Pc1PmWF6Hk6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "gAhw7gOZHjrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "lr = 0.001\n",
        "epoch = 10\n",
        "\n",
        "# Define Image data generator\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen =  ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcVOowieHkgY",
        "outputId": "adc9cf1d-304b-4db5-e5ca-70c72d77939c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 107 images belonging to 5 classes.\n",
            "Found 50 images belonging to 5 classes.\n",
            "Found 12 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load VGG16\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Add global average layer\n",
        "net = base_model.output\n",
        "net = GlobalAveragePooling2D()(net)\n",
        "\n",
        "# Creat the new model with VGG16 (feature selection) + SVC (classifier)\n",
        "new_model = Model(inputs=base_model.input, outputs=net)\n",
        "#new_model.compile(optimizer=Adam(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "train_features = new_model.predict(train_generator)\n",
        "train_labels = train_generator.classes\n",
        "\n",
        "val_features = new_model.predict(val_generator)\n",
        "val_labels = val_generator.classes\n",
        "\n",
        "# Train SVM Classifier\n",
        "svm = SVC(kernel='linear')\n",
        "svm.fit(train_features, train_labels )"
      ],
      "metadata": {
        "id": "R3nEr5D7K9As"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and Evaluate the New_Model"
      ],
      "metadata": {
        "id": "O2vxjjDIO45g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on validation set\n",
        "val_accuracy = svm.score(val_features, val_labels)\n",
        "print(\"Validation Accuracy:\", val_accuracy)"
      ],
      "metadata": {
        "id": "_UjwIU5mU-Dz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}